"""
ğŸ”® ç°¡å˜äºˆæ¸¬ã‚¹ã‚¯ãƒªãƒ—ãƒˆ - å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ã¦ã¿ã‚ˆã†ï¼

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ã¦æ„Ÿæƒ…åˆ†æã‚’ç°¡å˜ã«è©¦ã›ã¾ã™ã€‚

å®Ÿè¡Œæ–¹æ³•:
    python quickstart_predict.py

å‰ææ¡ä»¶:
    - quickstart_simple.py ã‚’å®Ÿè¡Œæ¸ˆã¿
    - models/my-first-model/ ã«ãƒ¢ãƒ‡ãƒ«ãŒä¿å­˜ã•ã‚Œã¦ã„ã‚‹
"""

import os
import sys

print("=" * 60)
print("ğŸ”® æ„Ÿæƒ…åˆ†æAIã§éŠã‚“ã§ã¿ã‚ˆã†ï¼")
print("=" * 60)
print()

# =============================================================================
# ãƒ¢ãƒ‡ãƒ«ã®ç¢ºèª
# =============================================================================
model_path = "./models/my-first-model"

if not os.path.exists(model_path):
    print("âŒ ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    print()
    print("ã¾ãšä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ã¦ãã ã•ã„:")
    print("  python quickstart_simple.py")
    print()
    sys.exit(1)

print(f"âœ“ ãƒ¢ãƒ‡ãƒ«ã‚’ç™ºè¦‹: {model_path}")
print()

# =============================================================================
# ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®èª­ã¿è¾¼ã¿
# =============================================================================
print("ğŸ“¦ AIã‚’èµ·å‹•ã—ã¦ã„ã¾ã™...")

try:
    import torch
    from transformers import AutoTokenizer, AutoModelForSequenceClassification
except ImportError:
    print("âŒ ã‚¨ãƒ©ãƒ¼: å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
    print("ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„:")
    print("  pip install -r requirements.txt")
    sys.exit(1)

# =============================================================================
# ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
# =============================================================================
print("ğŸ¤– ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...")

try:
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForSequenceClassification.from_pretrained(model_path)
    model.to(device)
    model.eval()
    print("âœ“ ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿å®Œäº†ï¼")
    print()
except Exception as e:
    print(f"âŒ ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
    print(f"ã‚¨ãƒ©ãƒ¼è©³ç´°: {e}")
    sys.exit(1)

# =============================================================================
# äºˆæ¸¬é–¢æ•°
# =============================================================================
def predict_sentiment(text):
    """
    ãƒ†ã‚­ã‚¹ãƒˆã®æ„Ÿæƒ…ã‚’äºˆæ¸¬ã™ã‚‹é–¢æ•°

    Args:
        text: åˆ†æã—ãŸã„ãƒ†ã‚­ã‚¹ãƒˆ

    Returns:
        sentiment: "ãƒã‚¸ãƒ†ã‚£ãƒ–" ã¾ãŸã¯ "ãƒã‚¬ãƒ†ã‚£ãƒ–"
        confidence: ç¢ºä¿¡åº¦ï¼ˆ0ã€œ1ï¼‰
        positive_prob: ãƒã‚¸ãƒ†ã‚£ãƒ–ã®ç¢ºç‡
        negative_prob: ãƒã‚¬ãƒ†ã‚£ãƒ–ã®ç¢ºç‡
    """
    # ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚º
    inputs = tokenizer(
        text,
        return_tensors="pt",
        truncation=True,
        max_length=256,
        padding=True
    )
    inputs = {key: value.to(device) for key, value in inputs.items()}

    # äºˆæ¸¬
    with torch.no_grad():
        outputs = model(**inputs)
        probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)

    negative_prob = probabilities[0][0].item()
    positive_prob = probabilities[0][1].item()

    if positive_prob > negative_prob:
        sentiment = "ãƒã‚¸ãƒ†ã‚£ãƒ–"
        confidence = positive_prob
        emoji = "ğŸ˜Š"
    else:
        sentiment = "ãƒã‚¬ãƒ†ã‚£ãƒ–"
        confidence = negative_prob
        emoji = "ğŸ˜”"

    return sentiment, confidence, positive_prob, negative_prob, emoji

# =============================================================================
# ã‚µãƒ³ãƒ—ãƒ«äºˆæ¸¬
# =============================================================================
print("=" * 60)
print("ğŸ“ ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚­ã‚¹ãƒˆã§è©¦ã—ã¦ã¿ã¾ã—ã‚‡ã†")
print("=" * 60)
print()

sample_texts = [
    "This movie was absolutely fantastic! Best film I've seen this year!",
    "Terrible waste of time. I want my money back.",
    "It was okay, nothing special.",
    "Amazing performance by the actors. Highly recommended!",
    "Boring and predictable. Fell asleep halfway through.",
]

for i, text in enumerate(sample_texts, 1):
    sentiment, confidence, pos_prob, neg_prob, emoji = predict_sentiment(text)

    print(f"ã‚µãƒ³ãƒ—ãƒ« {i}:")
    print(f"  å…¥åŠ›: \"{text}\"")
    print(f"  çµæœ: {sentiment} {emoji} (ç¢ºä¿¡åº¦: {confidence:.1%})")
    print(f"  è©³ç´°: ãƒã‚¬ãƒ†ã‚£ãƒ– {neg_prob:.1%} | ãƒã‚¸ãƒ†ã‚£ãƒ– {pos_prob:.1%}")
    print()

# =============================================================================
# ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ¢ãƒ¼ãƒ‰
# =============================================================================
print("=" * 60)
print("âœ¨ ã‚ãªãŸã®ãƒ†ã‚­ã‚¹ãƒˆã§è©¦ã—ã¦ã¿ã¾ã—ã‚‡ã†ï¼")
print("=" * 60)
print()
print("ğŸ’¡ ãƒ’ãƒ³ãƒˆ:")
print("  - è‹±èªã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
print("  - æ˜ ç”»ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ã‚ˆã†ãªæ–‡ç« ãŒæœ€é©ã§ã™")
print("  - 'quit' ã¾ãŸã¯ 'exit' ã§çµ‚äº†")
print()

while True:
    try:
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
        user_input = input("ğŸ“ ã‚ãªãŸã®ãƒ†ã‚­ã‚¹ãƒˆ: ").strip()

        # çµ‚äº†ã‚³ãƒãƒ³ãƒ‰ã®ãƒã‚§ãƒƒã‚¯
        if user_input.lower() in ['quit', 'exit', 'q', 'çµ‚äº†']:
            print()
            print("ğŸ‘‹ ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸï¼ã¾ãŸã­ï¼")
            break

        # ç©ºå…¥åŠ›ã®ãƒã‚§ãƒƒã‚¯
        if not user_input:
            print("âš ï¸  ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            print()
            continue

        # äºˆæ¸¬å®Ÿè¡Œ
        sentiment, confidence, pos_prob, neg_prob, emoji = predict_sentiment(user_input)

        # çµæœè¡¨ç¤º
        print()
        print(f"ğŸ”® äºˆæ¸¬çµæœ:")
        print(f"  æ„Ÿæƒ…: {sentiment} {emoji}")
        print(f"  ç¢ºä¿¡åº¦: {confidence:.1%}")
        print()

        # è©³ç´°ãªåˆ†æ
        print(f"ğŸ“Š è©³ç´°:")
        print(f"  ãƒã‚¬ãƒ†ã‚£ãƒ–: {'â–ˆ' * int(neg_prob * 20)} {neg_prob:.1%}")
        print(f"  ãƒã‚¸ãƒ†ã‚£ãƒ–: {'â–ˆ' * int(pos_prob * 20)} {pos_prob:.1%}")
        print()

        # è§£é‡ˆã®ãƒ˜ãƒ«ãƒ—
        if confidence >= 0.9:
            print("ğŸ’¡ è§£é‡ˆ: AIã¯ã‹ãªã‚Šç¢ºä¿¡ã‚’æŒã£ã¦ã„ã¾ã™")
        elif confidence >= 0.7:
            print("ğŸ’¡ è§£é‡ˆ: AIã¯ã‚ã‚‹ç¨‹åº¦ç¢ºä¿¡ã—ã¦ã„ã¾ã™")
        else:
            print("ğŸ’¡ è§£é‡ˆ: AIã¯å°‘ã—è¿·ã£ã¦ã„ã‚‹ã‚ˆã†ã§ã™ï¼ˆä¸­ç«‹çš„ãªæ–‡ç« ã‹ã‚‚ï¼‰")

        print()
        print("-" * 60)
        print()

    except KeyboardInterrupt:
        print()
        print()
        print("ğŸ‘‹ ä¸­æ–­ã•ã‚Œã¾ã—ãŸã€‚ã¾ãŸã­ï¼")
        break
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        print()

# =============================================================================
# çµ‚äº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
# =============================================================================
print()
print("=" * 60)
print("âœ… äºˆæ¸¬ã‚¹ã‚¯ãƒªãƒ—ãƒˆçµ‚äº†")
print("=" * 60)
print()
print("ğŸ¯ æ¬¡ã«ã‚„ã£ã¦ã¿ã‚‹ã“ã¨:")
print("  1. ã‚ˆã‚Šé•·ãå­¦ç¿’ã—ã¦ã¿ã‚‹:")
print("     - config/beginner_config.yaml ã§ num_epochs ã‚’å¢—ã‚„ã™")
print()
print("  2. åˆ¥ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’è©¦ã™:")
print("     - è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã® dataset.name ã‚’å¤‰æ›´")
print()
print("  3. æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«ã§è©¦ã™:")
print("     - model.name ã‚’ 'cl-tohoku/bert-base-japanese' ã«å¤‰æ›´")
print()
print("ğŸ“š è©³ã—ã„æƒ…å ±:")
print("  - QUICKSTART.md")
print("  - docs/CONCEPTS.md")
print("=" * 60)
