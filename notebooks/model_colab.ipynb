{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# モデル定義モジュール\n",
                "\n",
                "Hugging Faceモデルのビルダークラスを提供します。\n",
                "\n",
                "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. 環境設定\n",
                "\n",
                "まず、GPUが有効になっているか確認します。\n",
                "\n",
                "**設定方法**: メニュー → ランタイム → ランタイムのタイプを変更 → GPU を選択"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# GPU確認\n",
                "import torch\n",
                "print(f\"GPU利用可能: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU名: {torch.cuda.get_device_name(0)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. ライブラリのインストール"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q transformers torch"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. ライブラリのインポート"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from typing import Optional\n",
                "from transformers import (\n",
                "    AutoModelForSequenceClassification,\n",
                "    AutoModelForTokenClassification,\n",
                "    AutoModelForQuestionAnswering,\n",
                "    AutoModelForCausalLM,\n",
                "    AutoConfig,\n",
                "    PreTrainedModel\n",
                ")\n",
                "import logging\n",
                "\n",
                "logging.basicConfig(level=logging.INFO)\n",
                "logger = logging.getLogger(__name__)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. ModelBuilderクラスの定義"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class ModelBuilder:\n",
                "    \"\"\"Hugging Faceモデルのビルダークラス\"\"\"\n",
                "\n",
                "    @staticmethod\n",
                "    def build_sequence_classification_model(\n",
                "        model_name: str,\n",
                "        num_labels: int,\n",
                "        pretrained: bool = True,\n",
                "        config_overrides: Optional[dict] = None\n",
                "    ) -> PreTrainedModel:\n",
                "        \"\"\"\n",
                "        テキスト分類モデルを構築\n",
                "\n",
                "        Args:\n",
                "            model_name: モデル名（例: \"bert-base-uncased\"）\n",
                "            num_labels: ラベル数\n",
                "            pretrained: 事前学習済みモデルを使用するか\n",
                "            config_overrides: 設定のオーバーライド\n",
                "\n",
                "        Returns:\n",
                "            分類モデル\n",
                "        \"\"\"\n",
                "        logger.info(f\"Building sequence classification model: {model_name}\")\n",
                "\n",
                "        try:\n",
                "            config = AutoConfig.from_pretrained(model_name)\n",
                "        except OSError as e:\n",
                "            logger.error(f\"Model '{model_name}' not found\")\n",
                "            logger.info(\"Available models: https://huggingface.co/models\")\n",
                "            raise ValueError(f\"Invalid model name: {model_name}\") from e\n",
                "\n",
                "        config.num_labels = num_labels\n",
                "\n",
                "        if config_overrides:\n",
                "            for key, value in config_overrides.items():\n",
                "                setattr(config, key, value)\n",
                "\n",
                "        try:\n",
                "            if pretrained:\n",
                "                model = AutoModelForSequenceClassification.from_pretrained(\n",
                "                    model_name,\n",
                "                    config=config,\n",
                "                    ignore_mismatched_sizes=True\n",
                "                )\n",
                "            else:\n",
                "                model = AutoModelForSequenceClassification.from_config(config)\n",
                "        except Exception as e:\n",
                "            logger.error(f\"Failed to load model: {e}\")\n",
                "            raise\n",
                "\n",
                "        logger.info(f\"Model built successfully with {num_labels} labels\")\n",
                "        return model\n",
                "\n",
                "    @staticmethod\n",
                "    def build_token_classification_model(\n",
                "        model_name: str,\n",
                "        num_labels: int,\n",
                "        pretrained: bool = True,\n",
                "        config_overrides: Optional[dict] = None\n",
                "    ) -> PreTrainedModel:\n",
                "        \"\"\"\n",
                "        トークン分類モデルを構築（NERなど）\n",
                "\n",
                "        Args:\n",
                "            model_name: モデル名\n",
                "            num_labels: ラベル数\n",
                "            pretrained: 事前学習済みモデルを使用するか\n",
                "            config_overrides: 設定のオーバーライド\n",
                "\n",
                "        Returns:\n",
                "            トークン分類モデル\n",
                "        \"\"\"\n",
                "        logger.info(f\"Building token classification model: {model_name}\")\n",
                "\n",
                "        try:\n",
                "            config = AutoConfig.from_pretrained(model_name)\n",
                "        except OSError as e:\n",
                "            logger.error(f\"Model '{model_name}' not found\")\n",
                "            logger.info(\"Available models: https://huggingface.co/models\")\n",
                "            raise ValueError(f\"Invalid model name: {model_name}\") from e\n",
                "\n",
                "        config.num_labels = num_labels\n",
                "\n",
                "        if config_overrides:\n",
                "            for key, value in config_overrides.items():\n",
                "                setattr(config, key, value)\n",
                "\n",
                "        try:\n",
                "            if pretrained:\n",
                "                model = AutoModelForTokenClassification.from_pretrained(\n",
                "                    model_name,\n",
                "                    config=config,\n",
                "                    ignore_mismatched_sizes=True\n",
                "                )\n",
                "            else:\n",
                "                model = AutoModelForTokenClassification.from_config(config)\n",
                "        except Exception as e:\n",
                "            logger.error(f\"Failed to load model: {e}\")\n",
                "            raise\n",
                "\n",
                "        logger.info(\"Token classification model built successfully\")\n",
                "        return model\n",
                "\n",
                "    @staticmethod\n",
                "    def build_qa_model(\n",
                "        model_name: str,\n",
                "        pretrained: bool = True,\n",
                "        config_overrides: Optional[dict] = None\n",
                "    ) -> PreTrainedModel:\n",
                "        \"\"\"\n",
                "        質問応答モデルを構築\n",
                "\n",
                "        Args:\n",
                "            model_name: モデル名\n",
                "            pretrained: 事前学習済みモデルを使用するか\n",
                "            config_overrides: 設定のオーバーライド\n",
                "\n",
                "        Returns:\n",
                "            質問応答モデル\n",
                "        \"\"\"\n",
                "        logger.info(f\"Building QA model: {model_name}\")\n",
                "\n",
                "        try:\n",
                "            config = AutoConfig.from_pretrained(model_name)\n",
                "        except OSError as e:\n",
                "            logger.error(f\"Model '{model_name}' not found\")\n",
                "            logger.info(\"Available models: https://huggingface.co/models\")\n",
                "            raise ValueError(f\"Invalid model name: {model_name}\") from e\n",
                "\n",
                "        if config_overrides:\n",
                "            for key, value in config_overrides.items():\n",
                "                setattr(config, key, value)\n",
                "\n",
                "        try:\n",
                "            if pretrained:\n",
                "                model = AutoModelForQuestionAnswering.from_pretrained(\n",
                "                    model_name,\n",
                "                    config=config,\n",
                "                    ignore_mismatched_sizes=True\n",
                "                )\n",
                "            else:\n",
                "                model = AutoModelForQuestionAnswering.from_config(config)\n",
                "        except Exception as e:\n",
                "            logger.error(f\"Failed to load model: {e}\")\n",
                "            raise\n",
                "\n",
                "        logger.info(\"QA model built successfully\")\n",
                "        return model\n",
                "\n",
                "    @staticmethod\n",
                "    def build_causal_lm_model(\n",
                "        model_name: str,\n",
                "        pretrained: bool = True,\n",
                "        config_overrides: Optional[dict] = None\n",
                "    ) -> PreTrainedModel:\n",
                "        \"\"\"\n",
                "        因果言語モデルを構築（GPTなど）\n",
                "\n",
                "        Args:\n",
                "            model_name: モデル名\n",
                "            pretrained: 事前学習済みモデルを使用するか\n",
                "            config_overrides: 設定のオーバーライド\n",
                "\n",
                "        Returns:\n",
                "            因果言語モデル\n",
                "        \"\"\"\n",
                "        logger.info(f\"Building Causal LM model: {model_name}\")\n",
                "\n",
                "        try:\n",
                "            config = AutoConfig.from_pretrained(model_name)\n",
                "        except OSError as e:\n",
                "            logger.error(f\"Model '{model_name}' not found\")\n",
                "            logger.info(\"Available models: https://huggingface.co/models\")\n",
                "            raise ValueError(f\"Invalid model name: {model_name}\") from e\n",
                "\n",
                "        if config_overrides:\n",
                "            for key, value in config_overrides.items():\n",
                "                setattr(config, key, value)\n",
                "\n",
                "        try:\n",
                "            if pretrained:\n",
                "                model = AutoModelForCausalLM.from_pretrained(\n",
                "                    model_name,\n",
                "                    config=config\n",
                "                )\n",
                "            else:\n",
                "                model = AutoModelForCausalLM.from_config(config)\n",
                "        except Exception as e:\n",
                "            logger.error(f\"Failed to load model: {e}\")\n",
                "            raise\n",
                "\n",
                "        logger.info(\"Causal LM model built successfully\")\n",
                "        return model"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. 使用例"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 使用例\n",
                "# テキスト分類モデルの構築\n",
                "model_name = \"distilbert-base-uncased\"\n",
                "num_labels = 2  # ポジティブ/ネガティブ\n",
                "\n",
                "model = ModelBuilder.build_sequence_classification_model(\n",
                "    model_name=model_name,\n",
                "    num_labels=num_labels,\n",
                "    pretrained=True\n",
                ")\n",
                "\n",
                "print(f\"モデル: {model_name}\")\n",
                "print(f\"パラメータ数: {model.num_parameters():,}\")\n",
                "print(f\"ラベル数: {num_labels}\")\n",
                "\n",
                "# モデルをGPUに移動\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "model.to(device)\n",
                "print(f\"使用デバイス: {device}\")"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
