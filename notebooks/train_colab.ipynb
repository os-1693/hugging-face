{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# モデル学習スクリプト\n",
                "\n",
                "Hugging Faceモデルを学習するためのスクリプトです。\n",
                "\n",
                "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. 環境設定\n",
                "\n",
                "まず、GPUが有効になっているか確認します。\n",
                "\n",
                "**設定方法**: メニュー → ランタイム → ランタイムのタイプを変更 → GPU を選択"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# GPU確認\n",
                "import torch\n",
                "print(f\"GPU利用可能: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU名: {torch.cuda.get_device_name(0)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. ライブラリのインストール"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q transformers datasets accelerate evaluate"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. ライブラリのインポート"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import argparse\n",
                "import logging\n",
                "import os\n",
                "from typing import Any, Dict, Optional\n",
                "\n",
                "import evaluate\n",
                "import numpy as np\n",
                "import torch\n",
                "import yaml\n",
                "from transformers import (\n",
                "    AutoTokenizer,\n",
                "    EarlyStoppingCallback,\n",
                "    Trainer,\n",
                "    TrainingArguments,\n",
                "    set_seed,\n",
                ")\n",
                "\n",
                "logging.basicConfig(\n",
                "    level=logging.INFO, format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
                ")\n",
                "logger = logging.getLogger(__name__)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. 学習関数の定義"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_config(config_path: str) -> Dict[str, Any]:\n",
                "    \"\"\"\n",
                "    設定ファイルを読み込む\n",
                "\n",
                "    Args:\n",
                "        config_path: 設定ファイルのパス\n",
                "\n",
                "    Returns:\n",
                "        設定辞書\n",
                "    \"\"\"\n",
                "    with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
                "        config = yaml.safe_load(f)\n",
                "    return config\n",
                "\n",
                "\n",
                "def compute_metrics_classification(eval_pred):\n",
                "    \"\"\"\n",
                "    分類タスクのメトリクスを計算\n",
                "\n",
                "    Args:\n",
                "        eval_pred: 予測結果\n",
                "\n",
                "    Returns:\n",
                "        メトリクス辞書\n",
                "    \"\"\"\n",
                "    metric = evaluate.load(\"accuracy\")\n",
                "    logits, labels = eval_pred\n",
                "    predictions = np.argmax(logits, axis=-1)\n",
                "    return metric.compute(predictions=predictions, references=labels)\n",
                "\n",
                "\n",
                "def train(config: Dict[str, Any]):\n",
                "    \"\"\"\n",
                "    モデルの学習を実行\n",
                "\n",
                "    Args:\n",
                "        config: 設定辞書\n",
                "    \"\"\"\n",
                "    # シードの設定\n",
                "    set_seed(config.get(\"seed\", 42))\n",
                "\n",
                "    # デバイスの設定\n",
                "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "    logger.info(f\"Using device: {device}\")\n",
                "\n",
                "    # トークナイザーの読み込み\n",
                "    logger.info(f\"Loading tokenizer: {config['model']['name']}\")\n",
                "    tokenizer = AutoTokenizer.from_pretrained(config[\"model\"][\"name\"])\n",
                "\n",
                "    # データセットの準備（簡略化のため直接読み込み）\n",
                "    from datasets import load_dataset\n",
                "    dataset = load_dataset(config[\"dataset\"][\"name\"])\n",
                "    \n",
                "    # 前処理\n",
                "    def preprocess_function(examples):\n",
                "        return tokenizer(\n",
                "            examples['text'],\n",
                "            padding=\"max_length\",\n",
                "            truncation=True,\n",
                "            max_length=config[\"model\"].get(\"max_length\", 512),\n",
                "        )\n",
                "    \n",
                "    processed_dataset = dataset.map(\n",
                "        preprocess_function,\n",
                "        batched=True,\n",
                "        remove_columns=['text']\n",
                "    )\n",
                "\n",
                "    # モデルの構築\n",
                "    from transformers import AutoModelForSequenceClassification\n",
                "    model = AutoModelForSequenceClassification.from_pretrained(\n",
                "        config[\"model\"][\"name\"],\n",
                "        num_labels=config[\"model\"][\"num_labels\"],\n",
                "    )\n",
                "    model.to(device)\n",
                "\n",
                "    # 学習設定\n",
                "    training_config = config[\"training\"]\n",
                "    training_args = TrainingArguments(\n",
                "        output_dir=training_config[\"output_dir\"],\n",
                "        num_train_epochs=training_config[\"num_epochs\"],\n",
                "        per_device_train_batch_size=training_config[\"batch_size\"],\n",
                "        per_device_eval_batch_size=training_config[\"eval_batch_size\"],\n",
                "        learning_rate=training_config[\"learning_rate\"],\n",
                "        weight_decay=training_config.get(\"weight_decay\", 0.01),\n",
                "        evaluation_strategy=\"epoch\",\n",
                "        save_strategy=\"epoch\",\n",
                "        logging_steps=training_config.get(\"logging_steps\", 100),\n",
                "        load_best_model_at_end=True,\n",
                "        metric_for_best_model=\"accuracy\",\n",
                "        save_total_limit=training_config.get(\"save_total_limit\", 3),\n",
                "        fp16=torch.cuda.is_available(),\n",
                "        report_to=\"none\",\n",
                "        seed=config.get(\"seed\", 42),\n",
                "    )\n",
                "\n",
                "    # Trainerの初期化\n",
                "    trainer = Trainer(\n",
                "        model=model,\n",
                "        args=training_args,\n",
                "        train_dataset=processed_dataset['train'],\n",
                "        eval_dataset=processed_dataset.get('validation', processed_dataset.get('test')),\n",
                "        compute_metrics=compute_metrics_classification,\n",
                "    )\n",
                "\n",
                "    # 学習の開始\n",
                "    logger.info(\"Starting training...\")\n",
                "    train_result = trainer.train()\n",
                "\n",
                "    # 学習結果の保存\n",
                "    logger.info(\"Saving model...\")\n",
                "    trainer.save_model()\n",
                "    tokenizer.save_pretrained(training_config[\"output_dir\"])\n",
                "\n",
                "    # メトリクスの保存\n",
                "    metrics = train_result.metrics\n",
                "    trainer.log_metrics(\"train\", metrics)\n",
                "    trainer.save_metrics(\"train\", metrics)\n",
                "\n",
                "    # 評価\n",
                "    if \"test\" in processed_dataset:\n",
                "        logger.info(\"Evaluating on test set...\")\n",
                "        test_metrics = trainer.evaluate(processed_dataset[\"test\"])\n",
                "        trainer.log_metrics(\"test\", test_metrics)\n",
                "        trainer.save_metrics(\"test\", test_metrics)\n",
                "\n",
                "    logger.info(\"Training completed!\")\n",
                "    return train_result"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. 使用例"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 学習設定\n",
                "config = {\n",
                "    \"seed\": 42,\n",
                "    \"model\": {\n",
                "        \"name\": \"distilbert-base-uncased\",\n",
                "        \"num_labels\": 2,\n",
                "        \"max_length\": 256\n",
                "    },\n",
                "    \"dataset\": {\n",
                "        \"name\": \"imdb\"\n",
                "    },\n",
                "    \"training\": {\n",
                "        \"output_dir\": \"./results\",\n",
                "        \"num_epochs\": 1,  # デモ用に1エポック\n",
                "        \"batch_size\": 16,\n",
                "        \"eval_batch_size\": 32,\n",
                "        \"learning_rate\": 2e-5,\n",
                "        \"weight_decay\": 0.01,\n",
                "        \"logging_steps\": 100,\n",
                "        \"save_total_limit\": 2\n",
                "    }\n",
                "}\n",
                "\n",
                "# 学習の実行\n",
                "train_result = train(config)\n",
                "print(\"学習完了!\")\n",
                "print(f\"最終損失: {train_result.training_loss:.4f}\")"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
