{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Hugging Face 感情分析クイックスタート\n",
                "\n",
                "Google Colabで無料GPUを使って、AIモデルの学習を体験しましょう。\n",
                "\n",
                "**所要時間**: 約5分\n",
                "\n",
                "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. 環境設定\n",
                "\n",
                "まず、GPUが有効になっているか確認します。\n",
                "\n",
                "**設定方法**: メニュー → ランタイム → ランタイムのタイプを変更 → GPU を選択"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# GPU確認\n",
                "import torch\n",
                "print(f\"GPU利用可能: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU名: {torch.cuda.get_device_name(0)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. ライブラリのインストール"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q transformers datasets accelerate evaluate"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. ライブラリのインポート"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "from transformers import (\n",
                "    AutoTokenizer,\n",
                "    AutoModelForSequenceClassification,\n",
                "    TrainingArguments,\n",
                "    Trainer,\n",
                "    set_seed\n",
                ")\n",
                "from datasets import load_dataset\n",
                "import evaluate\n",
                "import numpy as np\n",
                "\n",
                "# 再現性のためシード固定\n",
                "set_seed(42)\n",
                "\n",
                "# デバイス確認\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "print(f\"使用デバイス: {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. データセットの読み込み\n",
                "\n",
                "IMDb映画レビューデータセット（英語）を使用します。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# データセット読み込み（少量版）\n",
                "# データセット全体をロードしてシャッフル\n",
                "full_dataset = load_dataset(\"imdb\")\n",
                "shuffled_train = full_dataset[\"train\"].shuffle(seed=42)\n",
                "shuffled_test = full_dataset[\"test\"].shuffle(seed=42)\n",
                "\n",
                "# バランスの取れたデータセットを作成\n",
                "dataset = {\n",
                "    \"train\": shuffled_train.select(range(1000)),\n",
                "    \"test\": shuffled_test.select(range(200)),\n",
                "}\n",
                "\n",
                "print(f\"訓練データ: {len(dataset['train'])}件\")\n",
                "print(f\"テストデータ: {len(dataset['test'])}件\")\n",
                "\n",
                "# サンプル表示\n",
                "print(f\"\\n例: {dataset['train'][0]['text'][:100]}...\")\n",
                "print(f\"ラベル: {'ポジティブ' if dataset['train'][0]['label'] == 1 else 'ネガティブ'}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. モデルとトークナイザーの準備"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# モデル名（軽量版BERT）\n",
                "model_name = \"distilbert-base-uncased\"\n",
                "\n",
                "# トークナイザーとモデルの読み込み\n",
                "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
                "model = AutoModelForSequenceClassification.from_pretrained(\n",
                "    model_name,\n",
                "    num_labels=2\n",
                ")\n",
                "model.to(device)\n",
                "\n",
                "print(f\"モデル: {model_name}\")\n",
                "print(f\"パラメータ数: {model.num_parameters():,}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. データの前処理"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def preprocess_function(examples):\n",
                "    return tokenizer(\n",
                "        examples['text'],\n",
                "        padding=\"max_length\",\n",
                "        truncation=True,\n",
                "        max_length=256\n",
                "    )\n",
                "\n",
                "# 前処理適用\n",
                "tokenized_dataset = dataset.map(\n",
                "    preprocess_function,\n",
                "    batched=True,\n",
                "    remove_columns=['text']\n",
                ")\n",
                "\n",
                "print(\"前処理完了\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. 評価関数の定義"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 評価メトリクス\n",
                "accuracy_metric = evaluate.load(\"accuracy\")\n",
                "\n",
                "def compute_metrics(eval_pred):\n",
                "    logits, labels = eval_pred\n",
                "    predictions = np.argmax(logits, axis=-1)\n",
                "    return accuracy_metric.compute(predictions=predictions, references=labels)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. 学習の設定と実行"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 学習設定\n",
                "training_args = TrainingArguments(\n",
                "    output_dir=\"./results\",\n",
                "    num_train_epochs=2,\n",
                "    per_device_train_batch_size=16,\n",
                "    per_device_eval_batch_size=32,\n",
                "    learning_rate=2e-5,\n",
                "    weight_decay=0.01,\n",
                "    eval_strategy=\"epoch\",\n",
                "    save_strategy=\"epoch\",\n",
                "    logging_steps=50,\n",
                "    load_best_model_at_end=True,\n",
                "    fp16=torch.cuda.is_available(),  # GPU時は混合精度\n",
                "    report_to=\"none\",  # wandbなどのログを無効化\n",
                ")\n",
                "\n",
                "# Trainer初期化\n",
                "trainer = Trainer(\n",
                "    model=model,\n",
                "    args=training_args,\n",
                "    train_dataset=tokenized_dataset['train'],\n",
                "    eval_dataset=tokenized_dataset['test'],\n",
                "    compute_metrics=compute_metrics,\n",
                ")\n",
                "\n",
                "print(\"学習を開始します...\")\n",
                "trainer.train()\n",
                "print(\"学習完了!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. 評価結果の確認"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 評価\n",
                "eval_result = trainer.evaluate()\n",
                "\n",
                "print(\"=\" * 40)\n",
                "print(\"最終結果\")\n",
                "print(\"=\" * 40)\n",
                "print(f\"正解率: {eval_result['eval_accuracy']:.2%}\")\n",
                "print(f\"損失: {eval_result['eval_loss']:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. 実際に予測してみよう"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# テストテキスト\n",
                "test_texts = [\n",
                "    \"This movie was absolutely fantastic! I loved it.\",\n",
                "    \"Terrible movie. Complete waste of time.\",\n",
                "    \"It was okay, nothing special.\"\n",
                "]\n",
                "\n",
                "model.eval()\n",
                "for text in test_texts:\n",
                "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=256)\n",
                "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        outputs = model(**inputs)\n",
                "        probs = torch.softmax(outputs.logits, dim=-1)\n",
                "    \n",
                "    pred = \"ポジティブ\" if probs[0][1] > probs[0][0] else \"ネガティブ\"\n",
                "    conf = max(probs[0]).item()\n",
                "    \n",
                "    print(f\"入力: {text}\")\n",
                "    print(f\"予測: {pred} (確信度: {conf:.1%})\")\n",
                "    print(\"-\" * 50)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 次のステップ\n",
                "\n",
                "1. **データ量を増やす**: `train[:5000]` に変更\n",
                "2. **エポック数を増やす**: `num_train_epochs=5`\n",
                "3. **日本語モデルを試す**: `cl-tohoku/bert-base-japanese-v3`\n",
                "4. **モデルを保存**: `trainer.save_model(\"my-model\")`"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
